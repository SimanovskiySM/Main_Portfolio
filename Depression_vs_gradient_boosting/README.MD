# Сравнение бустинговых моделей. Описание проекта.

Ссылка на Kaggle: https://www.kaggle.com/datasets/hopesb/student-depression-dataset

В этом датасете собраны данные об учащихся, исследуемым бинарным признаком является наличие у них у диагностированной депрессии (столбец Depression, значение 1 - есть депрессия, значение 0 -депрессии нет). Входными признаками является собранная о них информация/
Предсказывать наличие депресси у учащегося будем путём бинарной классифкации с помощью бустинговых моделей: XGBoost, LightGBM и Catboost. Сравнивать их успешность работы с данным датасетом будем по метрике F1.

# Общие выводы.

Машинное обучение в очередной раз показало себя очень перспективным инструментом для применения в медицинской сфере, в данном случае - для своевременного обнаружения депрессии у учащихся. Модели, работа которых основана на градиентном бустинге, даже в ненастроенном варианте при хорошо собранных данных в данном случае дали прогнозы с относительно высокой точностью. Лучше все оказался классификатор CatBoost, который верно определил 88% опрошенных с диагностированной депрессией и 79% без таковой. Автоматическая настройка модели по трём основным гиперпараметрам с помощью библиотеки Optuna в данном случае даёт слишком малое улучшение итогового значения метрики, для дальнейшего улучшения модели нужна либо увеличение количества настраиваемых гиперпараметров,
  либо другие подходы (увеличение количества исследуемой информации, работа с признаками и т. д.).                                           
